{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "g7EcHa43PNjR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import keras.optimizer_v2.gradient_descent\n",
    "import numpy as np\n",
    "import skimage\n",
    "from matplotlib import pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VChXCovMPNjS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_similarity as tfsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JNQouFwnPNjU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfsim.utils.tf_cap_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KrS3xBdWPNjV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Clear out any old model state.\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dO0D4fhHPNjW",
    "outputId": "cfe7190b-8688-463c-cc64-8b02e4e45318",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.8.2\n",
      "TensorFlow Similarity 0.16.7\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"TensorFlow Similarity\", tfsim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['traindata/val/Tom Hanks/086_e7072dbb.jpg', 'traindata/val/Tom Hanks/091_da40c2a6.jpg', 'traindata/val/Tom Hanks/075_0268d466.jpg', 'traindata/val/Tom Hanks/027_82e30afe.jpg', 'traindata/val/Tom Hanks/062_41f18a02.jpg', 'traindata/val/Tom Hanks/058_450266ba.jpg', 'traindata/val/Tom Hanks/031_1d57bbbf.jpg', 'traindata/val/Tom Hanks/090_3c8ed08d.jpg', 'traindata/val/Tom Hanks/096_eb059e84.jpg', 'traindata/val/Tom Hanks/018_b7231fad.jpg', 'traindata/val/Tom Hanks/012_39efc245.jpg', 'traindata/val/Tom Hanks/070_316ffc8a.jpg', 'traindata/val/Tom Hanks/029_169c07b0.jpg', 'traindata/val/Tom Hanks/097_0c9b7ced.jpg', 'traindata/val/Tom Hanks/022_df2ce089.jpg', 'traindata/val/Tom Hanks/059_c7c906d9.jpg', 'traindata/val/Tom Hanks/001_986d6c22.jpg', 'traindata/val/Tom Hanks/081_ff5f08ea.jpg', 'traindata/val/Tom Hanks/088_78e9691e.jpg', 'traindata/val/Tom Hanks/094_ea1110a3.jpg', 'traindata/val/Tom Hanks/005_dac94cfe.jpg', 'traindata/val/Tom Hanks/077_351b17d6.jpg', 'traindata/val/Tom Hanks/014_ff388296.jpg', 'traindata/val/Tom Cruise/022_43b050c3.jpg', 'traindata/val/Tom Cruise/089_20b122f3.jpg', 'traindata/val/Tom Cruise/074_f29224ac.jpg', 'traindata/val/Tom Cruise/085_698d9a21.jpg', 'traindata/val/Tom Cruise/057_e3da0420.jpg', 'traindata/val/Tom Cruise/078_076c27b8.jpg', 'traindata/val/Tom Cruise/015_8adbc3ae.jpg', 'traindata/val/Tom Cruise/097_914cebdd.jpg', 'traindata/val/Tom Cruise/030_377fefef.jpg', 'traindata/val/Tom Cruise/091_a9736a22.jpg', 'traindata/val/Tom Cruise/072_dccafedf.jpg', 'traindata/val/Tom Cruise/001_08212dcd.jpg', 'traindata/val/Tom Cruise/080_566ea9e9.jpg', 'traindata/val/Tom Cruise/067_8dcd661e.jpg', 'traindata/val/Tom Cruise/005_2464c583.jpg', 'traindata/val/Tom Cruise/090_8f4eb0e6.jpg', 'traindata/val/Tom Cruise/094_2f713c67.jpg', 'traindata/val/Tom Cruise/032_5934eb7a.jpg', 'traindata/val/Tom Cruise/060_b53036a3.jpg', 'traindata/val/Tom Cruise/056_158d5258.jpg', 'traindata/val/Tom Cruise/012_900c5b05.jpg', 'traindata/val/Tom Cruise/019_99363fad.jpg', 'traindata/val/Tom Cruise/028_a41d259d.jpg', 'traindata/val/Tom Cruise/098_3790f566.jpg', 'traindata/val/Megan Fox/016_bd51d057.jpg', 'traindata/val/Megan Fox/033_4e5edeac.jpg', 'traindata/val/Megan Fox/086_b9831d16.jpg', 'traindata/val/Megan Fox/076_424b03b7.jpg', 'traindata/val/Megan Fox/070_4de04405.jpg', 'traindata/val/Megan Fox/005_9574c208.jpg', 'traindata/val/Megan Fox/098_24676238.jpg', 'traindata/val/Megan Fox/059_d09c7676.jpg', 'traindata/val/Megan Fox/029_19296e1d.jpg', 'traindata/val/Megan Fox/092_bbd39177.jpg', 'traindata/val/Megan Fox/097_e1dabc00.jpg', 'traindata/val/Megan Fox/063_10c723ae.jpg', 'traindata/val/Megan Fox/084_70354863.jpg', 'traindata/val/Megan Fox/031_d719ba67.jpg', 'traindata/val/Megan Fox/023_55dd20e3.jpg', 'traindata/val/Megan Fox/020_467a9bd7.jpg', 'traindata/val/Megan Fox/014_d6e920d4.jpg', 'traindata/val/Megan Fox/001_dfb62d96.jpg', 'traindata/val/Megan Fox/058_1b5b5422.jpg', 'traindata/val/Megan Fox/095_fc25a60b.jpg', 'traindata/val/Megan Fox/100_f0e45dd1.jpg', 'traindata/val/Megan Fox/079_4e33cd00.jpg', 'traindata/val/Denzel Washington/086_8eefe9d0.jpg', 'traindata/val/Denzel Washington/094_7858a9ff.jpg', 'traindata/val/Denzel Washington/031_2fe075a5.jpg', 'traindata/val/Denzel Washington/015_72bb2861.jpg', 'traindata/val/Denzel Washington/077_a0ceecbd.jpg', 'traindata/val/Denzel Washington/089_2539e4d9.jpg', 'traindata/val/Denzel Washington/022_b60724f6.jpg', 'traindata/val/Denzel Washington/013_5928728c.jpg', 'traindata/val/Denzel Washington/029_cf7e7736.jpg', 'traindata/val/Denzel Washington/019_330f0c75.jpg', 'traindata/val/Denzel Washington/066_0411d529.jpg', 'traindata/val/Denzel Washington/001_d3323f3c.jpg', 'traindata/val/Denzel Washington/027_c7a10f8d.jpg', 'traindata/val/Denzel Washington/005_cb37c7b2.jpg', 'traindata/val/Denzel Washington/096_9ff8b67f.jpg', 'traindata/val/Denzel Washington/059_3b848154.jpg', 'traindata/val/Denzel Washington/082_359c4774.jpg', 'traindata/val/Denzel Washington/087_cec971ab.jpg', 'traindata/val/Denzel Washington/073_2880f59c.jpg', 'traindata/val/Denzel Washington/097_b745e092.jpg', 'traindata/val/Denzel Washington/055_fbbcb3c7.jpg', 'traindata/val/Denzel Washington/071_30155b02.jpg', 'traindata/val/Denzel Washington/056_ccaa5638.jpg', 'traindata/val/Brad Pitt/012_8de7a736.jpg', 'traindata/val/Brad Pitt/005_02ab3a1b.jpg', 'traindata/val/Brad Pitt/097_df404aa1.jpg', 'traindata/val/Brad Pitt/096_b096ebfe.jpg', 'traindata/val/Brad Pitt/089_7a7d2c5d.jpg', 'traindata/val/Brad Pitt/055_14a5e7bc.jpg', 'traindata/val/Brad Pitt/058_ca613f72.jpg', 'traindata/val/Brad Pitt/079_e3171916.jpg', 'traindata/val/Brad Pitt/072_da45cf8f.jpg', 'traindata/val/Brad Pitt/084_4876da64.jpg', 'traindata/val/Brad Pitt/018_136dbb40.jpg', 'traindata/val/Brad Pitt/070_0acb9d53.jpg', 'traindata/val/Brad Pitt/030_716e4856.jpg', 'traindata/val/Brad Pitt/054_9f01aefa.jpg', 'traindata/val/Brad Pitt/028_181cbb8a.jpg', 'traindata/val/Brad Pitt/077_ddf0abd8.jpg', 'traindata/val/Brad Pitt/094_16e562f0.jpg', 'traindata/val/Brad Pitt/090_12e1f614.jpg', 'traindata/val/Brad Pitt/014_871b0d80.jpg', 'traindata/val/Brad Pitt/001_c04300ef.jpg', 'traindata/val/Brad Pitt/065_34848907.jpg', 'traindata/val/Brad Pitt/091_8561b34e.jpg', 'traindata/val/Brad Pitt/021_143b276f.jpg', 'traindata/val/Brad Pitt/026_805241a7.jpg', 'traindata/val/Johnny Depp/026_20c41942.jpg', 'traindata/val/Johnny Depp/014_68248214.jpg', 'traindata/val/Johnny Depp/089_2f2e823a.jpg', 'traindata/val/Johnny Depp/098_16b30dda.jpg', 'traindata/val/Johnny Depp/071_d3036d43.jpg', 'traindata/val/Johnny Depp/012_563f0843.jpg', 'traindata/val/Johnny Depp/085_e9f6ea07.jpg', 'traindata/val/Johnny Depp/094_42a45a8d.jpg', 'traindata/val/Johnny Depp/097_11415581.jpg', 'traindata/val/Johnny Depp/055_cf9af56c.jpg', 'traindata/val/Johnny Depp/090_c5d1d9eb.jpg', 'traindata/val/Johnny Depp/028_ce59b46d.jpg', 'traindata/val/Johnny Depp/030_ddacf348.jpg', 'traindata/val/Johnny Depp/088_1fcc7b2c.jpg', 'traindata/val/Johnny Depp/001_2288a4f6.jpg', 'traindata/val/Johnny Depp/029_30aec656.jpg', 'traindata/val/Johnny Depp/077_5cbf1ecc.jpg', 'traindata/val/Johnny Depp/018_14e5366f.jpg', 'traindata/val/Johnny Depp/005_9406f32d.jpg', 'traindata/val/Johnny Depp/056_c5e6243c.jpg', 'traindata/val/Johnny Depp/066_653f2a94.jpg', 'traindata/val/Johnny Depp/073_71584704.jpg', 'traindata/val/Johnny Depp/059_27a0e6f1.jpg', 'traindata/val/Johnny Depp/079_241963dc.jpg', 'traindata/val/Robert Downey Jr/012_e3dd7d69.jpg', 'traindata/val/Robert Downey Jr/022_64141160.jpg', 'traindata/val/Robert Downey Jr/001_a51bb26a.jpg', 'traindata/val/Robert Downey Jr/082_d9295121.jpg', 'traindata/val/Robert Downey Jr/097_833dba65.jpg', 'traindata/val/Robert Downey Jr/058_4ed85318.jpg', 'traindata/val/Robert Downey Jr/027_25f404f4.jpg', 'traindata/val/Robert Downey Jr/090_d347e279.jpg', 'traindata/val/Robert Downey Jr/061_b36635a2.jpg', 'traindata/val/Robert Downey Jr/098_b78efdc8.jpg', 'traindata/val/Robert Downey Jr/077_a908452a.jpg', 'traindata/val/Robert Downey Jr/029_02077e81.jpg', 'traindata/val/Robert Downey Jr/032_ac85b92c.jpg', 'traindata/val/Robert Downey Jr/018_0d23eccd.jpg', 'traindata/val/Robert Downey Jr/057_8572457a.jpg', 'traindata/val/Robert Downey Jr/068_72330c63.jpg', 'traindata/val/Robert Downey Jr/086_9b44c502.jpg', 'traindata/val/Robert Downey Jr/075_dff1c336.jpg', 'traindata/val/Robert Downey Jr/005_8af3cada.jpg', 'traindata/val/Robert Downey Jr/091_5307a177.jpg', 'traindata/val/Robert Downey Jr/095_dd07ab81.jpg', 'traindata/val/Robert Downey Jr/014_75f93e62.jpg', 'traindata/val/Robert Downey Jr/030_adb3aa0e.jpg', 'traindata/val/Scarlett Johansson/032_7c1161c1.jpg', 'traindata/val/Scarlett Johansson/021_0b380404.jpg', 'traindata/val/Scarlett Johansson/061_bf06c582.jpg', 'traindata/val/Scarlett Johansson/058_90a2b4d3.jpg', 'traindata/val/Scarlett Johansson/198_e056989e.jpg', 'traindata/val/Scarlett Johansson/094_ad3f1b0c.jpg', 'traindata/val/Scarlett Johansson/002_ea6e259d.jpg', 'traindata/val/Scarlett Johansson/023_e57cc529.jpg', 'traindata/val/Scarlett Johansson/095_0c6b7820.jpg', 'traindata/val/Scarlett Johansson/025_cd625bef.jpg', 'traindata/val/Scarlett Johansson/057_317143a9.jpg', 'traindata/val/Scarlett Johansson/158_b3e56fdd.jpg', 'traindata/val/Scarlett Johansson/110_9b23a9ba.jpg', 'traindata/val/Scarlett Johansson/190_1d7fca25.jpg', 'traindata/val/Scarlett Johansson/154_42de3f25.jpg', 'traindata/val/Scarlett Johansson/018_a532251b.jpg', 'traindata/val/Scarlett Johansson/140_080f3112.jpg', 'traindata/val/Scarlett Johansson/024_6c2e4da8.jpg', 'traindata/val/Scarlett Johansson/132_a2dd114f.jpg', 'traindata/val/Scarlett Johansson/192_6f142457.jpg', 'traindata/val/Scarlett Johansson/099_1046eb6d.jpg', 'traindata/val/Scarlett Johansson/152_a5f9d1a6.jpg', 'traindata/val/Scarlett Johansson/008_10846cce.jpg', 'traindata/val/Scarlett Johansson/183_065be5ce.jpg', 'traindata/val/Scarlett Johansson/111_13e0f9a5.jpg', 'traindata/val/Scarlett Johansson/012_be8f222c.jpg', 'traindata/val/Scarlett Johansson/009_fc574624.jpg', 'traindata/val/Scarlett Johansson/040_9848047c.jpg', 'traindata/val/Scarlett Johansson/187_b430a570.jpg', 'traindata/val/Scarlett Johansson/089_244148b6.jpg', 'traindata/val/Scarlett Johansson/060_003a8f0c.jpg', 'traindata/val/Scarlett Johansson/100_0bc6635b.jpg', 'traindata/val/Scarlett Johansson/041_9913ca04.jpg', 'traindata/val/Scarlett Johansson/168_aaaf41c4.jpg', 'traindata/val/Scarlett Johansson/051_f852bd6d.jpg', 'traindata/val/Scarlett Johansson/090_8e8d0b5c.jpg', 'traindata/val/Scarlett Johansson/078_6b17a035.jpg', 'traindata/val/Scarlett Johansson/144_99c39c61.jpg', 'traindata/val/Scarlett Johansson/155_a52e96fe.jpg', 'traindata/val/Scarlett Johansson/091_764fb4f6.jpg', 'traindata/val/Scarlett Johansson/073_884e445b.jpg', 'traindata/val/Scarlett Johansson/170_1156035a.jpg', 'traindata/val/Scarlett Johansson/052_89d1073b.jpg', 'traindata/val/Scarlett Johansson/146_bcd22d45.jpg', 'traindata/val/Scarlett Johansson/117_3aea85fd.jpg', 'traindata/val/Scarlett Johansson/184_2137d05c.jpg', 'traindata/val/Scarlett Johansson/069_da4a375a.jpg', 'traindata/val/Scarlett Johansson/120_e5229f43.jpg', 'traindata/val/Angelina Jolie/056_97412d14.jpg', 'traindata/val/Angelina Jolie/030_66bddeb6.jpg', 'traindata/val/Angelina Jolie/094_c255b703.jpg', 'traindata/val/Angelina Jolie/072_8d068904.jpg', 'traindata/val/Angelina Jolie/074_0ec79719.jpg', 'traindata/val/Angelina Jolie/091_b5b4a62f.jpg', 'traindata/val/Angelina Jolie/067_ff52c2fe.jpg', 'traindata/val/Angelina Jolie/059_df425619.jpg', 'traindata/val/Angelina Jolie/090_da55509f.jpg', 'traindata/val/Angelina Jolie/085_f579db33.jpg', 'traindata/val/Angelina Jolie/080_e998ab00.jpg', 'traindata/val/Angelina Jolie/028_6a0ff8de.jpg', 'traindata/val/Angelina Jolie/096_75710434.jpg', 'traindata/val/Angelina Jolie/005_582c121a.jpg', 'traindata/val/Angelina Jolie/001_fe3347c0.jpg', 'traindata/val/Angelina Jolie/012_cfcd4007.jpg', 'traindata/val/Angelina Jolie/014_0d29db88.jpg', 'traindata/val/Angelina Jolie/078_044866e7.jpg', 'traindata/val/Angelina Jolie/055_aaaf063c.jpg', 'traindata/val/Angelina Jolie/098_dd1405fc.jpg', 'traindata/val/Angelina Jolie/018_fcafe1a8.jpg', 'traindata/val/Angelina Jolie/029_f2882b0d.jpg', 'traindata/val/Angelina Jolie/026_2828fcaf.jpg', 'traindata/val/Angelina Jolie/089_33e36564.jpg', 'traindata/val/Will Smith/014_f512d81c.jpg', 'traindata/val/Will Smith/057_faaa39ed.jpg', 'traindata/val/Will Smith/018_d5d389eb.jpg', 'traindata/val/Will Smith/029_09dcae68.jpg', 'traindata/val/Will Smith/087_6eba84a6.jpg', 'traindata/val/Will Smith/077_eb907a5f.jpg', 'traindata/val/Will Smith/089_97f39eb8.jpg', 'traindata/val/Will Smith/081_8dc3b149.jpg', 'traindata/val/Will Smith/021_3cf2aa92.jpg', 'traindata/val/Will Smith/091_082508dd.jpg', 'traindata/val/Will Smith/012_19e90fb6.jpg', 'traindata/val/Will Smith/027_803986e2.jpg', 'traindata/val/Will Smith/068_b778f382.jpg', 'traindata/val/Will Smith/092_498e6999.jpg', 'traindata/val/Will Smith/098_6f416b6a.jpg', 'traindata/val/Will Smith/074_61fe25d9.jpg', 'traindata/val/Will Smith/001_beebcee2.jpg', 'traindata/val/Will Smith/097_5c18be93.jpg', 'traindata/val/Will Smith/032_2899cee6.jpg', 'traindata/val/Will Smith/058_38b80eed.jpg', 'traindata/val/Will Smith/061_4385aa8d.jpg', 'traindata/val/Will Smith/005_37066c18.jpg', 'traindata/val/Will Smith/095_8a2dfab4.jpg', 'traindata/val/Natalie Portman/091_6985bf33.jpg', 'traindata/val/Natalie Portman/097_ec4fe2e9.jpg', 'traindata/val/Natalie Portman/029_2f4ca9e5.jpg', 'traindata/val/Natalie Portman/095_00690f89.jpg', 'traindata/val/Natalie Portman/001_9cd1160a.jpg', 'traindata/val/Natalie Portman/086_e6cb087e.jpg', 'traindata/val/Natalie Portman/081_bdc0cced.jpg', 'traindata/val/Natalie Portman/058_75c1a7f6.jpg', 'traindata/val/Natalie Portman/012_36c352b5.jpg', 'traindata/val/Natalie Portman/019_58c32d1b.jpg', 'traindata/val/Natalie Portman/098_d82741fc.jpg', 'traindata/val/Natalie Portman/014_2c325a73.jpg', 'traindata/val/Natalie Portman/005_f8b76ad5.jpg', 'traindata/val/Natalie Portman/031_972f207f.jpg', 'traindata/val/Natalie Portman/092_a67b993f.jpg', 'traindata/val/Natalie Portman/075_2b6154c6.jpg', 'traindata/val/Natalie Portman/027_ffa4c67b.jpg', 'traindata/val/Natalie Portman/057_a633d34a.jpg', 'traindata/val/Natalie Portman/089_7a22dd1d.jpg', 'traindata/val/Natalie Portman/061_029fc37f.jpg', 'traindata/val/Natalie Portman/022_0b6f73be.jpg', 'traindata/val/Natalie Portman/069_c9e3207d.jpg', 'traindata/val/Natalie Portman/077_e589a0e2.jpg', 'traindata/val/Hugh Jackman/074_d205687c.jpg', 'traindata/val/Hugh Jackman/077_08ff1da6.jpg', 'traindata/val/Hugh Jackman/098_5cb67f9d.jpg', 'traindata/val/Hugh Jackman/018_3bdca9f6.jpg', 'traindata/val/Hugh Jackman/094_bcb2a8f4.jpg', 'traindata/val/Hugh Jackman/081_9f4d7bcb.jpg', 'traindata/val/Hugh Jackman/086_269deff5.jpg', 'traindata/val/Hugh Jackman/032_0e6a520a.jpg', 'traindata/val/Hugh Jackman/090_916ba69a.jpg', 'traindata/val/Hugh Jackman/012_b33b05c6.jpg', 'traindata/val/Hugh Jackman/068_474081ea.jpg', 'traindata/val/Hugh Jackman/022_9b0e7dc8.jpg', 'traindata/val/Hugh Jackman/030_c2291830.jpg', 'traindata/val/Hugh Jackman/097_21a9bff5.jpg', 'traindata/val/Hugh Jackman/001_9adc92c2.jpg', 'traindata/val/Hugh Jackman/057_6aecaa18.jpg', 'traindata/val/Hugh Jackman/014_07f2f9cb.jpg', 'traindata/val/Hugh Jackman/091_2ace2ad8.jpg', 'traindata/val/Hugh Jackman/061_2de5a089.jpg', 'traindata/val/Hugh Jackman/028_7214d33e.jpg', 'traindata/val/Hugh Jackman/088_2ec116fe.jpg', 'traindata/val/Hugh Jackman/058_48dcb96c.jpg', 'traindata/val/Hugh Jackman/005_3ba56da0.jpg', 'traindata/val/Leonardo DiCaprio/059_1027f3c2.jpg', 'traindata/val/Leonardo DiCaprio/073_42e32f65.jpg', 'traindata/val/Leonardo DiCaprio/014_539eee38.jpg', 'traindata/val/Leonardo DiCaprio/098_f0bc37c7.jpg', 'traindata/val/Leonardo DiCaprio/022_66e94346.jpg', 'traindata/val/Leonardo DiCaprio/029_8522ebc8.jpg', 'traindata/val/Leonardo DiCaprio/097_1837d89e.jpg', 'traindata/val/Leonardo DiCaprio/027_7094e195.jpg', 'traindata/val/Leonardo DiCaprio/068_a703f85f.jpg', 'traindata/val/Leonardo DiCaprio/019_78627223.jpg', 'traindata/val/Leonardo DiCaprio/005_7fe5b764.jpg', 'traindata/val/Leonardo DiCaprio/089_8e7757ef.jpg', 'traindata/val/Leonardo DiCaprio/092_cbc6d525.jpg', 'traindata/val/Leonardo DiCaprio/079_6ec91919.jpg', 'traindata/val/Leonardo DiCaprio/031_28a211fc.jpg', 'traindata/val/Leonardo DiCaprio/012_d7aea1e6.jpg', 'traindata/val/Leonardo DiCaprio/095_7ffaffe6.jpg', 'traindata/val/Leonardo DiCaprio/056_13edab75.jpg', 'traindata/val/Leonardo DiCaprio/055_ba4ace00.jpg', 'traindata/val/Leonardo DiCaprio/091_e39f525d.jpg', 'traindata/val/Leonardo DiCaprio/084_08314073.jpg', 'traindata/val/Leonardo DiCaprio/001_08194468.jpg', 'traindata/val/Leonardo DiCaprio/075_c2c28553.jpg', 'traindata/val/Jennifer Lawrence/060_bb963eed.jpg', 'traindata/val/Jennifer Lawrence/097_f19b4cfc.jpg', 'traindata/val/Jennifer Lawrence/005_7f198c47.jpg', 'traindata/val/Jennifer Lawrence/057_3911a64f.jpg', 'traindata/val/Jennifer Lawrence/012_12d61e14.jpg', 'traindata/val/Jennifer Lawrence/018_2974b20a.jpg', 'traindata/val/Jennifer Lawrence/056_f22ab393.jpg', 'traindata/val/Jennifer Lawrence/073_2c17626c.jpg', 'traindata/val/Jennifer Lawrence/092_aebdc10e.jpg', 'traindata/val/Jennifer Lawrence/031_0785344e.jpg', 'traindata/val/Jennifer Lawrence/100_6882dc21.jpg', 'traindata/val/Jennifer Lawrence/014_0100b141.jpg', 'traindata/val/Jennifer Lawrence/091_e8f3497f.jpg', 'traindata/val/Jennifer Lawrence/028_7191558a.jpg', 'traindata/val/Jennifer Lawrence/068_9718f48b.jpg', 'traindata/val/Jennifer Lawrence/095_0ccffcb8.jpg', 'traindata/val/Jennifer Lawrence/026_cf5be1f1.jpg', 'traindata/val/Jennifer Lawrence/079_cf4c7dee.jpg', 'traindata/val/Jennifer Lawrence/001_21a7d5e6.jpg', 'traindata/val/Jennifer Lawrence/090_14fe77d5.jpg', 'traindata/val/Jennifer Lawrence/075_5a5afdfa.jpg', 'traindata/val/Jennifer Lawrence/029_7cc8d551.jpg', 'traindata/val/Jennifer Lawrence/098_fa237ecc.jpg', 'traindata/val/Jennifer Lawrence/021_2eaafb9f.jpg', 'traindata/val/Sandra Bullock/013_3ef4eccf.jpg', 'traindata/val/Sandra Bullock/001_5ef3e95c.jpg', 'traindata/val/Sandra Bullock/084_6b81d36b.jpg', 'traindata/val/Sandra Bullock/099_d22b8b8b.jpg', 'traindata/val/Sandra Bullock/063_8e71347c.jpg', 'traindata/val/Sandra Bullock/032_f3773aa6.jpg', 'traindata/val/Sandra Bullock/028_5388c983.jpg', 'traindata/val/Sandra Bullock/092_8c255f73.jpg', 'traindata/val/Sandra Bullock/015_8a94d8c7.jpg', 'traindata/val/Sandra Bullock/059_b5b38942.jpg', 'traindata/val/Sandra Bullock/060_a274185c.jpg', 'traindata/val/Sandra Bullock/019_7a6470ab.jpg', 'traindata/val/Sandra Bullock/071_45baaf8f.jpg', 'traindata/val/Sandra Bullock/005_b0b4e2fa.jpg', 'traindata/val/Sandra Bullock/022_1c07f2df.jpg', 'traindata/val/Sandra Bullock/089_15cc8ac7.jpg', 'traindata/val/Sandra Bullock/078_d9a9ca25.jpg', 'traindata/val/Sandra Bullock/076_469143b0.jpg', 'traindata/val/Sandra Bullock/097_783b21f0.jpg', 'traindata/val/Sandra Bullock/082_24911cfe.jpg', 'traindata/val/Sandra Bullock/095_bcb2e593.jpg', 'traindata/val/Sandra Bullock/030_642eaf93.jpg', 'traindata/val/Nicole Kidman/092_62cd3fd3.jpg', 'traindata/val/Nicole Kidman/086_9b7a99a3.jpg', 'traindata/val/Nicole Kidman/090_8252f095.jpg', 'traindata/val/Nicole Kidman/058_a5eb69fb.jpg', 'traindata/val/Nicole Kidman/014_bbe9116e.jpg', 'traindata/val/Nicole Kidman/012_b26d9a9d.jpg', 'traindata/val/Nicole Kidman/018_9d776351.jpg', 'traindata/val/Nicole Kidman/028_febcaba9.jpg', 'traindata/val/Nicole Kidman/005_0623ac96.jpg', 'traindata/val/Nicole Kidman/068_7c776799.jpg', 'traindata/val/Nicole Kidman/073_0684f60d.jpg', 'traindata/val/Nicole Kidman/061_edc107ca.jpg', 'traindata/val/Nicole Kidman/095_bf0ae200.jpg', 'traindata/val/Nicole Kidman/001_504d320d.jpg', 'traindata/val/Nicole Kidman/026_0d302cfc.jpg', 'traindata/val/Nicole Kidman/079_e3bf147b.jpg', 'traindata/val/Nicole Kidman/081_412ea8f5.jpg', 'traindata/val/Nicole Kidman/097_d6f6f9cf.jpg', 'traindata/val/Nicole Kidman/030_ea2a7db1.jpg', 'traindata/val/Nicole Kidman/057_72a1674e.jpg', 'traindata/val/Nicole Kidman/075_4b3fac46.jpg', 'traindata/val/Nicole Kidman/021_7b2a627c.jpg', 'traindata/val/Nicole Kidman/098_5224652a.jpg', 'traindata/val/Nicole Kidman/091_d4af6789.jpg', 'traindata/val/Kate Winslet/077_9bcf9b8c.jpg', 'traindata/val/Kate Winslet/028_669aab36.jpg', 'traindata/val/Kate Winslet/057_b1a0b23b.jpg', 'traindata/val/Kate Winslet/095_8ffab61d.jpg', 'traindata/val/Kate Winslet/087_4ec19123.jpg', 'traindata/val/Kate Winslet/064_1b7da2f6.jpg', 'traindata/val/Kate Winslet/005_93b2fce9.jpg', 'traindata/val/Kate Winslet/001_5992faf7.jpg', 'traindata/val/Kate Winslet/085_c957f9b7.jpg', 'traindata/val/Kate Winslet/026_92cdfd7c.jpg', 'traindata/val/Kate Winslet/092_7716bdbb.jpg', 'traindata/val/Kate Winslet/098_f4f39b7c.jpg', 'traindata/val/Kate Winslet/018_738a56fd.jpg', 'traindata/val/Kate Winslet/097_51a924c1.jpg', 'traindata/val/Kate Winslet/014_76fd590c.jpg', 'traindata/val/Kate Winslet/100_6cee7c73.jpg', 'traindata/val/Kate Winslet/059_089c6dcd.jpg', 'traindata/val/Kate Winslet/030_92cca8fa.jpg', 'traindata/val/Kate Winslet/072_5372b2f8.jpg', 'traindata/val/Kate Winslet/081_e9a7882a.jpg', 'traindata/val/Kate Winslet/021_40180588.jpg', 'traindata/val/Kate Winslet/012_a2bb90dc.jpg']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pathlib\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "# def prepare(path, array):\n",
    "#     for folder in os.listdir(path):\n",
    "#         sub_path = path + \"/\" + folder\n",
    "#         for img in os.listdir(sub_path):\n",
    "#             image_path = sub_path + \"/\" + img\n",
    "#             try:\n",
    "#                 img_arr = io.imread(image_path)\n",
    "#             except:\n",
    "#                 print(\"pass\")\n",
    "#                 pass\n",
    "#             img_arr = resize(img_arr, output_shape=(224, 224))\n",
    "#             array.append(img_arr)\n",
    "def get_images_and_labels(data_root_dir):\n",
    "    # get all images' paths (format: string)\n",
    "    data_root = pathlib.Path(data_root_dir)\n",
    "    all_image_path = [str(path) for path in list(data_root.glob('*/*'))]\n",
    "\n",
    "    # get labels' names\n",
    "    label_names = sorted(item.name for item in data_root.glob('*/'))\n",
    "    # dict: {label : index}\n",
    "    label_to_index = dict((label, index) for index, label in enumerate(label_names))\n",
    "    # get all images' labels\n",
    "    all_image_label = [label_to_index[pathlib.Path(single_image_path).parent.name] for single_image_path in all_image_path]\n",
    "\n",
    "    return all_image_path, all_image_label\n",
    "\n",
    "\n",
    "x_train_paths , y_train = get_images_and_labels(\"./traindata/val\")\n",
    "x_test_paths , y_test = get_images_and_labels(\"./traindata/test\")\n",
    "print(x_train_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#\n",
    "# datagen = ImageDataGenerator()\n",
    "# train_gen = datagen.flow_from_directory(directory=train_path, target_size=(224, 224), class_mode=\"categorical\")\n",
    "# valid_gen = datagen.flow_from_directory(directory=val_path, target_size=(224, 224), class_mode=\"categorical\")\n",
    "# print(train_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTj58DHcPNjY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*For* a similarity model to learn efficiently, each batch must contains at least 2 examples of each class.\n",
    "\n",
    "To make this easy, tf_similarity offers `Samplers()` that enable you to set both the number of classes and the minimum number of examples of each class per batch. Here we are creating a `MultiShotMemorySampler()` which allows you to sample an in-memory dataset and provides multiple examples per class.\n",
    "\n",
    "TensorFlow Similarity provides various samplers to accomodate different requirements, including a `SingleShotMemorySampler()` for single-shot learning, a `TFDatasetMultiShotMemorySampler()` that integrate directly with the TensorFlow datasets catalogue, and a `TFRecordDatasetSampler()` that allows you to sample from very large datasets stored on disk as TFRecords shards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:00<00:00, 325.15it/s]\n",
      "100%|██████████| 419/419 [00:01<00:00, 317.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 15 15 15 15 15 14 14 14 14 14 14  8  8  8  8  8  8  2  2  2  2  2  2\n",
      "  1  1  1  1  1  1  5  5  5  5  5  5 11 11 11 11 11 13 13 13 13 13 13 13\n",
      " 13 13 13 13  0  0  0  0  0  0 16 16 16 16 16 16  9  9  9  9  9  9  3  3\n",
      "  3  3  3  3  7  7  7  7  7  7  4  4  4  4  4 12 12 12 12 12 12 10 10 10\n",
      " 10 10 10  6  6  6  6  6  6]\n",
      "\n",
      "The initial batch size is 34 (17 classes * 2 examples per class) with 0 augmenters\n"
     ]
    },
    {
     "data": {
      "text/plain": "filtering examples:   0%|          | 0/419 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "352f6cba3ccf4f4a87e83ce519870f1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "selecting classes:   0%|          | 0/17 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f661763c85a43709662705ef19078fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "gather examples:   0%|          | 0/419 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4eb75f3c2b7b4ef4b767ba26fe369f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "indexing classes:   0%|          | 0/419 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a1d934c62424823be02fb4f6f54decb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "x_test = []\n",
    "x_train=[]\n",
    "for img_path in tqdm(x_test_paths):\n",
    "    x_test.append(io.imread(img_path))\n",
    "for img_path in tqdm(x_train_paths):\n",
    "    x_train.append(io.imread(img_path))\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "print(y_test)\n",
    "sampler = tfsim.samplers.MultiShotMemorySampler(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    classes_per_batch=17,\n",
    ")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAzDjUZQPNjZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGk2wmPCPNjZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model definition\n",
    "\n",
    "`SimilarityModel()` models extend `tensorflow.keras.model.Model` with additional features and functionality that allow you to index and search for similar looking examples.\n",
    "\n",
    "As visible in the model definition below, similarity models output a 64 dimensional float embedding using the `MetricEmbedding()` layers. This layer is a Dense layer with L2 normalization. Thanks to the loss, the model learns to minimize the distance between similar examples and maximize the distance between dissimilar examples. As a result, the distance between examples in the embedding space is meaningful; the smaller the distance the more similar the examples are. \n",
    "\n",
    "Being able to use a distance as a meaningful proxy for how similar two examples are, is what enables the fast ANN (aproximate nearest neighbor) search. Using a sub-linear ANN search instead of a standard quadratic NN search is what allows deep similarity search to scale to millions of items. The built in memory index used in this notebook scales to a million indexed examples very easily... if you have enough RAM :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hnUuF8jAPNjZ",
    "outputId": "641c2a60-c1cd-4ce6-c1c9-5fe30111b8de",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"similarity_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, None, None, 1792)  17673823 \n",
      "                                                                 \n",
      " gem_pool (GeneralizedMeanPo  (None, 1792)             0         \n",
      " oling2D)                                                        \n",
      "                                                                 \n",
      " metric_embedding (MetricEmb  (None, 512)              918016    \n",
      " edding)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,591,839\n",
      "Trainable params: 918,016\n",
      "Non-trainable params: 17,673,823\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow_similarity.losses import MultiSimilarityLoss\n",
    "from keras import layers, Sequential\n",
    "from keras.applications import inception_v3\n",
    "from tensorflow_similarity.layers import MetricEmbedding\n",
    "from tensorflow_similarity.models import SimilarityModel\n",
    "\n",
    "input_shape = (380, 380, 3)\n",
    "\n",
    "\n",
    "# def get_inception():\n",
    "#     inception_model = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False,input_shape=input_shape)\n",
    "#     for layer in inception_model.layers[:240]:\n",
    "#         layer.trainable = False\n",
    "#     for layer in inception_model.layers[240:]:\n",
    "#         layer.trainable = True\n",
    "#     return inception_model\n",
    "#\n",
    "\n",
    "# def get_model():\n",
    "#     # inception = get_inception()\n",
    "#     backbone = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "#\n",
    "#     for layer in backbone.layers[:190]:\n",
    "#             layer.trainable = False\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     x = backbone(inputs)\n",
    "#     x = layers.Rescaling(1 / 255)(x)\n",
    "#     x = layers.Dense(512)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "#     x = layers.Dense(256)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "#     # smaller embeddings will have faster lookup times while a larger embedding will improve the accuracy up to a point.\n",
    "#     outputs = MetricEmbedding(512)(x)\n",
    "#     return SimilarityModel(inputs, outputs)\n",
    "#\n",
    "#\n",
    "#\n",
    "# model = get_model()\n",
    "model = tfsim.architectures.EfficientNetSim(\n",
    "   input_shape=input_shape,\n",
    "    variant=\"B4\",\n",
    "    embedding_size=512,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hsnuvmb-PNjZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loss definition\n",
    "\n",
    "Overall what makes Metric losses different from tradional losses is that:\n",
    "- **They expect different inputs.** Instead of having the prediction equal the true values, they expect embeddings as `y_preds` and the id (as an int32) of the class as `y_true`. \n",
    "- **They require a distance.** You need to specify which `distance` function to use to compute the distance between embeddings. `cosine` is usually a great starting point and the default.\n",
    "\n",
    "In this example we are using the `MultiSimilarityLoss()`. This loss takes a weighted combination of all valid positive and negative pairs, making it one of the best loss that you can use for similarity training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "g7KPk1ydPNja",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = tfsim.losses.MultiSimilarityLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjY1Ey03PNja",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compilation\n",
    "\n",
    "Tensorflow similarity use an extended `compile()` method that allows you to optionally specify `distance_metrics` (metrics that are computed over the distance between the embeddings), and the distance to use for the indexer.\n",
    "\n",
    "By default the `compile()` method tries to infer what type of distance you are using by looking at the first loss specified. If you use multiple losses, and the distance loss is not the first one, then you need to specify the distance function used as `distance=` parameter in the compile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "U74F8ELBPNja",
    "outputId": "41a52163-b59e-494d-b358-7f5d4bbd68c8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance metric automatically set to cosine use the distance arg to override.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizer_v2.adam import Adam\n",
    "\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kca3JDTnPNjb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "Similarity models are trained like normal models. \n",
    "\n",
    "**NOTE**: don't expect the validation loss to decrease too much here because we only use a subset of the classes within the train data but include all classes in the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [],
    "id": "nQeAQh4mPNjb",
    "outputId": "c42a07be-7ba9-423f-85f6-8f223331a1cd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_14226/3185232169.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mEPOCHS\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m2\u001B[0m  \u001B[0;31m# @param {type:\"integer\"}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mhistory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msampler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mEPOCHS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1382\u001B[0m                 _r=1):\n\u001B[1;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1384\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1385\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 915\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    916\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    978\u001B[0m         \u001B[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m         \u001B[0;31m# stateless function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 980\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    981\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    982\u001B[0m       \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   2956\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 2957\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   2958\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2959\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1852\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1853\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1854\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1856\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    502\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    503\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 504\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    505\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 55\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     56\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "EPOCHS = 2  # @param {type:\"integer\"}\n",
    "\n",
    "history = model.fit(sampler, epochs=EPOCHS, verbose=1,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_yAIoccUPNjb",
    "outputId": "93d3d101-5fd5-449b-a4ea-789094a28fb5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# expect loss: 0.14 / val_loss: 0.33\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.legend([\"loss\"])\n",
    "plt.title(f\"Loss: {loss.name} \")\n",
    "plt.show()\n",
    "\n",
    "save_path = \"models/23.09:58\"  # @param {type:\"string\"}\n",
    "model.save(save_path, save_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Indexing\n",
    "\n",
    "Indexing is where things get different from traditional classification models. Because the model learned to output an embedding that represent the example position within the learned metric space, we need a way to find which known example(s) are the closest to determine the class of the query example (aka nearest neighbors classication).\n",
    "\n",
    "To do so, **we are creating an index of known examples from all the classes present in the dataset**. We do this by taking a total of **200 examples from the train dataset which amount to 20 examples per class** and we use the `index()` method of the model to build the index.\n",
    "\n",
    "we store the images (x_index) as data in the index `(data=x_index)` so that we can display them later. Here the images are small so its not an issue but in general, be careful while storing a lot of data in the index to avoid blewing up your memory. You might consider using a different `Store()` backend if you have to store and serve very large indexes.\n",
    "\n",
    "Indexing more examples per class will help increase the accuracy/generalization, as having more variations improves the classifier \"knowledge\" of what variations to expect.\n",
    "\n",
    "Reseting the index is not needed for the first run; however we always calling it to ensure we start the evaluation with a clean index in case of a partial re-run."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "filtering examples:   0%|          | 0/1187 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "932617c657044ba5a9dfb574850b1bbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "selecting classes:   0%|          | 0/17 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a046ae66c16d480f90392f15977c290b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "gather examples:   0%|          | 0/51 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1141ccf1f85404683b82eadb6e21294"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Indexing 51 points]\n",
      "|-Computing embeddings\n"
     ]
    }
   ],
   "source": [
    "x_index, y_index = tfsim.samplers.select_examples(x_train, y_train, class_list[:17], 3)\n",
    "model.reset_index()\n",
    "model.index(x_index, y_index, data=x_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calibration\n",
    "\n",
    "To be able to tell if an example matches a given class, we first need to `calibrate()` the model to find the optimal cut point. This cut point is the maximum distance below which returned neighbors are of the same class. Increasing the threshold improves the recall at the expense of the precision.\n",
    "\n",
    "By default, the calibration uses the F-score classification metric to optimally balance out the precsion and recalll; however, you can speficy your own target and change the calibration metric to better suite your usecase."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, y_train = sampler.get_slice()\n",
    "calibration = model.calibrate(\n",
    "    x_train,\n",
    "    y_train\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Querying\n",
    "\n",
    "To \"classify\" examples, we need to lookup their *k* [nearest neighbors](https://scikit-learn.org/stable/modules/neighbors.html) in the index.\n",
    "\n",
    "Here we going to query a single random example for each class from the test dataset using `select_examples()` and then find their nearest neighbors using the `lookup()` function.\n",
    "\n",
    "**NOTE** By default the classes 8, 5, 0, and 4 were not seen during training, but we still get reasonable matches as visible in the image below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# re-run to test on other examples\n",
    "num_neighbors = 5\n",
    "\n",
    "# select\n",
    "x_display, y_display = tfsim.samplers.select_examples(x_train, y_train, class_list[:3], 1)\n",
    "\n",
    "# lookup nearest neighbors in the index\n",
    "nns = model.lookup(x_display, k=num_neighbors)\n",
    "\n",
    "# # display\n",
    "\n",
    "# img = io.imread(\"./traindata/test/Angelina Jolie/004_f61e7d0c.jpg\")\n",
    "# img = resize(img,(299,299))\n",
    "# nns = model.single_lookup(img,3)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "for idx in np.argsort(y_display):\n",
    "    tfsim.visualization.viz_neigbors_imgs(x_display[idx], y_display[idx], nns[idx], fig_size=(16, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4VgX1iBPNjd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metrics ploting\n",
    "\n",
    "Let's plot the performance metrics to see how they evolve as the distance threshold increases. \n",
    "\n",
    "We clearly see an inflection point where the precision and recall intersect, however, this is not the `optimal_cutpoint` because the recall continues to increase faster than the precision decreases. Different usecases will have different performance profiles, which why each model needs to be calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6Uytgi1PNjd",
    "outputId": "a0bd8e21-4610-42de-f557-7a4ef6db56bb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = calibration.thresholds[\"distance\"]\n",
    "ax.plot(x, calibration.thresholds[\"precision\"], label=\"precision\")\n",
    "ax.plot(x, calibration.thresholds[\"recall\"], label=\"recall\")\n",
    "ax.plot(x, calibration.thresholds[\"f1\"], label=\"f1 score\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Metric evolution as distance increase\")\n",
    "ax.set_xlabel(\"Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWtoupBrPNje",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Precision/Recall curve\n",
    "\n",
    "We can see in the precision/recall curve below, that the curve is not smooth.\n",
    "This is because the recall can improve independently of the precision causing a \n",
    "seesaw pattern.\n",
    "\n",
    "Additionally, the model does extremly well on known classes and less well on \n",
    "the unseen ones, which contributes to the flat curve at the begining followed \n",
    "by a sharp decline as the distance threshold increases and \n",
    "examples are further away from the indexed examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poG3IHeFPNje",
    "outputId": "47e37e13-3b93-4391-c1b4-a3ce58929ba1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(calibration.thresholds[\"recall\"], calibration.thresholds[\"precision\"])\n",
    "ax.set_title(\"Precision recall curve\")\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGSfJBsaPNje",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Matching\n",
    "\n",
    "The purpose of `match()` is to allow you to use your similarity models to make \n",
    "classification predictions. It accomplishes this by finding the nearest neigbors\n",
    "for a set of query examples and returning an infered label based on neighbors \n",
    "labels and the matching strategy used (MatchNearest by default).\n",
    "\n",
    "Note: unlike traditional models, the  `match()` method potentially returns -1 \n",
    "when there are no indexed examples below the cutpoint threshold. The -1 class\n",
    "should be treated as \"unknown\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4cvA-DRPNjf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Matching in practice\n",
    "Let's now match a 10 examples to see how you can use the model `match()` method \n",
    "in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtCHeX2PPNjf",
    "outputId": "8a4bbdba-1789-4ce9-9d5b-d719b25778ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "x_test, y_test = val_sampler.get_slice()\n",
    "num_matches = 10  # @param {type:\"integer\"}\n",
    "\n",
    "matches = model.match(x_test, cutpoint=\"optimal\")\n",
    "rows = []\n",
    "for idx, match in enumerate(matches):\n",
    "    rows.append([match, y_test[idx], match == y_test[idx]])\n",
    "print(tabulate(rows, headers=[\"Predicted\", \"Expected\", \"Correct\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIbfQx6YPNjf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### confusion matrix\n",
    "Now that we have a better sense of what the match() method does, let's scale up \n",
    "to a few thousand samples per class and evaluate how good our model is at \n",
    "predicting the correct classes.\n",
    "\n",
    "As expected, while the model prediction performance is very good, its not \n",
    "competitive with a classification model. However this lower accuracy comes with \n",
    "the unique advantage that the model is able to classify classes \n",
    "that were not seen during training.\n",
    "\n",
    "\n",
    "**NOTE** `tf.math.confusion_matrix` doesn't support negative classes, so we are going to use **class 10 as our unknown class**. As mentioned earlier, unknown examples are \n",
    "any testing example for which the closest neighbor distance is greater than the cutpoint threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dj5KXW4ZPNjf",
    "outputId": "76ffd9da-e0ae-4175-c2b0-46190d34b5dc",
    "colab": {
     "referenced_widgets": [
      "bec0f76442da4cbc9bf15554def224d0",
      "39bbf5e6f0384505927de7f153c3bb3a",
      "bb7de5bdbd4a482a8e74d2f6d3b21f74"
     ]
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# used to label in images in the viz_neighbors_imgs plots\n",
    "# note we added a 11th classes for unknown\n",
    "labels = train_gen.class_indices\n",
    "num_examples_per_class = 3\n",
    "cutpoint = \"optimal\"\n",
    "\n",
    "x_confusion, y_confusion = tfsim.samplers.select_examples(val_x, val_y, class_list, num_examples_per_class)\n",
    "\n",
    "matches = model.match(x_confusion, cutpoint=cutpoint, no_match_label=10)\n",
    "cm = tfsim.visualization.confusion_matrix(\n",
    "    matches,\n",
    "    y_confusion,\n",
    "    labels=labels,\n",
    "    title=\"Confusin matrix for cutpoint:%s\" % cutpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-5Y5RrcPNjf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Index information\n",
    "\n",
    "Following `model.summary()` you can get information about the index configuration and its performance using `index_summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZmzv55iPNjg",
    "outputId": "1e2f8c79-cf16-465b-8f94-8d9ab341f1b0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.index_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xbb2NndbPNjg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saving and reloading\n",
    "Saving and reloading the model works as you would expected: \n",
    "\n",
    "- `model.save(path, save_index=True)`: save the model and the index on disk. By default the index is compressed but this can be disabled by setting `compressed=False`\n",
    "\n",
    "- `model = tf.keras.model.load_model(path, custom_objects={\"SimilarityModel\": tfsim.models.SimilarityModel})` reload the model. \n",
    "\n",
    "- **NOTE**: We need to pass `SimilarityModel` as a custom object to ensure that Keras knows about the index methods.\n",
    "\n",
    "- `model.load_index(path)` Is requried to reload the index. \n",
    "\n",
    "- `model.save_index(path)` and `model.load_index(path)` allows to save/reload an index independently of saving/loading a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ll9atYcDPNjg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLpgT4_NPNjg",
    "outputId": "bc58e764-2892-4307-e5b7-3585204caa72",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save the model and the index\n",
    "save_path = \"models/17clas-5sample-3 epoch 4000spe\"  # @param {type:\"string\"}\n",
    "model.save(save_path, save_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONBOCrAzPNjg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBcrmrhAPNjg",
    "outputId": "eab0e879-52f6-4213-cb66-56c913c585cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reload the model\n",
    "reloaded_model = tf.keras.models.load_model(\n",
    "    save_path,\n",
    "    custom_objects={\"SimilarityModel\": tfsim.models.SimilarityModel},\n",
    ")\n",
    "# reload the index\n",
    "reloaded_model.load_index(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDMQzmjJPNjh",
    "outputId": "b7c52904-1add-43c7-efb9-930ce8b49a37",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check the index is back\n",
    "reloaded_model.index_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr1bNUdcPNjh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Query reloaded model\n",
    "Querying the reloaded model with its reload index works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "250_lkDaPNjh",
    "outputId": "f29b9ad7-cc47-4f37-c94b-a3661eea31a3",
    "colab": {
     "referenced_widgets": [
      "f9baf9da862d47e08ff1ac8014be7c14",
      "388de1bdd7df4354818fdade3163b73d",
      "b3ab698a9b2c435dad4ec14332f8fd9d",
      "307484ce7b3c4588816851bdefec4395"
     ]
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# re-run to test on other examples\n",
    "num_neighbors = 5\n",
    "\n",
    "# select\n",
    "x_display, y_display = tfsim.samplers.select_examples(test_x, test_y, CLASSES, 1)\n",
    "\n",
    "# lookup the nearest neighbors\n",
    "nns = model.lookup(x_display, k=num_neighbors)\n",
    "\n",
    "# display\n",
    "for idx in np.argsort(y_display):\n",
    "    tfsim.visualization.viz_neigbors_imgs(x_display[idx], y_display[idx], nns[idx], fig_size=(16, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra9U4lKtPNji",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Thanks you for following this tutorial till the end. If you are interested in learning about TensorFlow Similarity advanced features, you can checkout our other notebooks."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "interpreter": {
   "hash": "cada0c3e68bbe3038c05f3f13c34d05fb5411cc128b62a4a529880c33c3268c3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "beb34c979f53df918eee6ac62e82d9c0beb9e6590c67a50c4f7c01f004ba70dc"
   }
  },
  "colab": {
   "name": "supervised_hello_world.ipynb",
   "provenance": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "b9511c3e8e5e4e7eaad1773a76be5af5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ece471e77d174008a3aad8d59bfc5d41",
       "IPY_MODEL_7fa7e457aca34fc49beae293e6db7d29",
       "IPY_MODEL_f85ab45c60d341608b5177c8df48ef40"
      ],
      "layout": "IPY_MODEL_16a5b6d8e4f04a32bc46bb7d3f295860"
     }
    },
    "ece471e77d174008a3aad8d59bfc5d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d087cd7d6da64a75a7baaabb8503463f",
      "placeholder": "​",
      "style": "IPY_MODEL_6f4e340ef16c49589dea576e8548de45",
      "value": "filtering examples: 100%"
     }
    },
    "7fa7e457aca34fc49beae293e6db7d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07313c305c0841eebb22696a992a444a",
      "max": 5717,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c49b9d1950147579d8796ce949b1a89",
      "value": 5717
     }
    },
    "f85ab45c60d341608b5177c8df48ef40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24adc96b3fbf444f9285e3a5a5ca583f",
      "placeholder": "​",
      "style": "IPY_MODEL_4f1719af24d04250b8f71b0d17d84d54",
      "value": " 5717/5717 [00:00&lt;00:00, 77726.43it/s]"
     }
    },
    "16a5b6d8e4f04a32bc46bb7d3f295860": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d087cd7d6da64a75a7baaabb8503463f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f4e340ef16c49589dea576e8548de45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "07313c305c0841eebb22696a992a444a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c49b9d1950147579d8796ce949b1a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24adc96b3fbf444f9285e3a5a5ca583f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1719af24d04250b8f71b0d17d84d54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d2e2975398a4fbe99d01541ec39f43a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d7990511bad4fbab902487152f95836",
       "IPY_MODEL_0e25c895f18343fc834d7e39f51cb5bb",
       "IPY_MODEL_375bb31b44ac47f0b7cb8d35a321cb81"
      ],
      "layout": "IPY_MODEL_e52822bd0619485d94509f97e7247240"
     }
    },
    "9d7990511bad4fbab902487152f95836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8494742d761a4aecbb22831fb94341f3",
      "placeholder": "​",
      "style": "IPY_MODEL_2f917ff1856546e89450ab999d2cb0e3",
      "value": "selecting classes: 100%"
     }
    },
    "0e25c895f18343fc834d7e39f51cb5bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9a7b0fa2d7147d59fa5c308f2820a7c",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_623d509f12df4aedaec9bf65a1b04379",
      "value": 6
     }
    },
    "375bb31b44ac47f0b7cb8d35a321cb81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd00fe7a9e094c0d9a51d096ba435acc",
      "placeholder": "​",
      "style": "IPY_MODEL_87f4af21e52548199de6441a9588f30c",
      "value": " 6/6 [00:00&lt;00:00, 100.87it/s]"
     }
    },
    "e52822bd0619485d94509f97e7247240": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8494742d761a4aecbb22831fb94341f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f917ff1856546e89450ab999d2cb0e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9a7b0fa2d7147d59fa5c308f2820a7c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "623d509f12df4aedaec9bf65a1b04379": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd00fe7a9e094c0d9a51d096ba435acc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87f4af21e52548199de6441a9588f30c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d59a70d2b4d34cc1b846c83a4bb64fea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6df17f3bfc1247bbba03507710da0543",
       "IPY_MODEL_99e21ad742ad402fbadc71d3bfadd466",
       "IPY_MODEL_6bcb9c6639cb4917b0ef0cb17d37489c"
      ],
      "layout": "IPY_MODEL_aaa4089a1f204ad2a422a7efc7054b11"
     }
    },
    "6df17f3bfc1247bbba03507710da0543": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21810c29476741d09c923f281a9b7524",
      "placeholder": "​",
      "style": "IPY_MODEL_e6ecab905c824783817b94a7f927d164",
      "value": "gather examples: 100%"
     }
    },
    "99e21ad742ad402fbadc71d3bfadd466": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bda614ad601443695bdf3bba8c18a43",
      "max": 948,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77303c4c6ebf47e2bfbf5bff612d6573",
      "value": 948
     }
    },
    "6bcb9c6639cb4917b0ef0cb17d37489c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac1c8bcbe53a40d69ef10e3423e2e39c",
      "placeholder": "​",
      "style": "IPY_MODEL_789aee269d6a41c09f498efbcd146740",
      "value": " 948/948 [00:00&lt;00:00, 15369.63it/s]"
     }
    },
    "aaa4089a1f204ad2a422a7efc7054b11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21810c29476741d09c923f281a9b7524": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6ecab905c824783817b94a7f927d164": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bda614ad601443695bdf3bba8c18a43": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77303c4c6ebf47e2bfbf5bff612d6573": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ac1c8bcbe53a40d69ef10e3423e2e39c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "789aee269d6a41c09f498efbcd146740": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "147f2b78abff4a779634425f2910eb84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ae276ac9335481485d8f981e6d548c7",
       "IPY_MODEL_dd393f56b5e14f81a562e96ebef73aef",
       "IPY_MODEL_6f1dd1ffe7d743f2a882f68db9ae704b"
      ],
      "layout": "IPY_MODEL_450a53392bbc42e88ef1be5bfd899376"
     }
    },
    "4ae276ac9335481485d8f981e6d548c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa0b34b81962469a846556c4906a9025",
      "placeholder": "​",
      "style": "IPY_MODEL_104af2739eaa44fa835f1f541ae95fcc",
      "value": "indexing classes: 100%"
     }
    },
    "dd393f56b5e14f81a562e96ebef73aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e0769bf3caa4da1abefe19fbfc39ba2",
      "max": 948,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f572f222d39466fb435feb545d2657e",
      "value": 948
     }
    },
    "6f1dd1ffe7d743f2a882f68db9ae704b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d701d0822d41c992898abfb84a82e0",
      "placeholder": "​",
      "style": "IPY_MODEL_160d9d12f3d44cac8be6a430b335d5c2",
      "value": " 948/948 [00:00&lt;00:00, 17114.08it/s]"
     }
    },
    "450a53392bbc42e88ef1be5bfd899376": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa0b34b81962469a846556c4906a9025": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "104af2739eaa44fa835f1f541ae95fcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e0769bf3caa4da1abefe19fbfc39ba2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f572f222d39466fb435feb545d2657e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b6d701d0822d41c992898abfb84a82e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "160d9d12f3d44cac8be6a430b335d5c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}